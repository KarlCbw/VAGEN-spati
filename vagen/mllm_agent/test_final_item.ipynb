{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verl.utils import hf_tokenizer, hf_processor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
    "processor = hf_processor(model_name)\n",
    "tokenizer = hf_tokenizer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import verl.utils.torch_functional as verl_F\n",
    "import torch\n",
    "from verl.utils.model import compute_position_id_with_mask\n",
    "response_with_chat_template='Abc def'\n",
    "prompt_with_chat_template='ascas'                  \n",
    "input_ids_response, attention_mask_response = verl_F.tokenize_and_postprocess_data(prompt=response_with_chat_template,\n",
    "                                                                         tokenizer=tokenizer,\n",
    "                                                                         max_length=10,\n",
    "                                                                         pad_token_id=tokenizer.pad_token_id,\n",
    "                                                                         left_pad=False,\n",
    "                                                                         truncation='error')\n",
    "input_ids_prompt, attention_mask_prompt = verl_F.tokenize_and_postprocess_data(prompt=prompt_with_chat_template,\n",
    "                                                                         tokenizer=tokenizer,\n",
    "                                                                         max_length=10,\n",
    "                                                                         pad_token_id=tokenizer.pad_token_id,\n",
    "                                                                         left_pad=True,\n",
    "                                                                         truncation='error')\n",
    "attention_mask_prompt=torch.zeros_like(input_ids_prompt) # All prompt will be masked\n",
    "\n",
    "\n",
    "\n",
    "input_ids_prompt=input_ids_prompt[0]\n",
    "attention_mask_prompt=attention_mask_prompt[0]\n",
    "input_ids_response=input_ids_response[0]\n",
    "attention_mask_response=attention_mask_response[0]\n",
    "loss_mask_prompt = torch.zeros_like(attention_mask_prompt)\n",
    "\n",
    "\n",
    "input_ids = torch.cat([input_ids_prompt, input_ids_response], dim=-1)\n",
    "attention_mask = torch.cat([attention_mask_prompt, attention_mask_response], dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "position_ids_prompt = compute_position_id_with_mask(attention_mask_prompt)\n",
    "\n",
    "response_length = input_ids_response.shape[0]\n",
    "delta_position_id = torch.arange(1, response_length + 1, device=position_ids_prompt.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_position_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_prompt[-1]=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_response = position_ids_prompt[-1:] + delta_position_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13, 14, 15, 16, 17, 18, 19, 20])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_ids_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attention_mask[:10])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:input_ids.shape:torch.Size([1, 1024])\n",
      "I love you<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "new_input_ids, new_attention_mask, new_loss_mask=loss_mask(input_ids, attention_mask)\n",
    "print(tokenizer.decode(new_input_ids[0][:30]))\n",
    "print(new_attention_mask[0][:30])\n",
    "print(new_loss_mask[0][:30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vagen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
