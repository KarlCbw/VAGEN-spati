{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verl.utils import hf_tokenizer, hf_processor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<image1asdasdqwa>', '<image2>', '<image3>']\n"
     ]
    }
   ],
   "source": [
    "text_template = \"The quick brown fox jumps over the lazy dog.<image1asdasdqwa>, <image2>, <image3>.\"\n",
    "import re\n",
    "image_keys=re.findall(r'<image[a-zA-Z0-9]*>', text_template)\n",
    "print(image_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
    "processor = hf_processor(model_name)\n",
    "tokenizer = hf_tokenizer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mask(input_ids, attention_mask):\n",
    "    sptk_b = tokenizer.convert_tokens_to_ids('<|box_start|>')\n",
    "    sptk_e = tokenizer.convert_tokens_to_ids('<|box_end|>')\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    print(f\"DEBUG:input_ids.shape:{input_ids.shape}\")\n",
    "    batch_size = input_ids.shape[0]\n",
    "    seq_len = input_ids.shape[1]\n",
    "    \n",
    "    # Initialize output tensors with same shape as inputs\n",
    "    new_input_ids = input_ids.clone()\n",
    "    new_attention_mask = attention_mask.clone()\n",
    "    loss_mask = torch.zeros_like(input_ids)\n",
    "    new_loss_mask = torch.zeros_like(input_ids)\n",
    "    # Process each example in the batch\n",
    "    for b in range(batch_size):\n",
    "        # Count right padding tokens using attention mask\n",
    "        right_pad_tokens = (new_input_ids[b] == pad_token_id).sum().item()\n",
    "        \n",
    "        # Assert that initial padding tokens have attention mask of 0\n",
    "        assert torch.all(attention_mask[b, -right_pad_tokens:] == 0), \"right padding tokens must have attention mask of 0\"\n",
    "        \n",
    "        # Find special token indices\n",
    "        sptk_b_indices = (input_ids[b] == sptk_b).nonzero().flatten()\n",
    "        sptk_e_indices = (input_ids[b] == sptk_e).nonzero().flatten()\n",
    "        \n",
    "        # Create a mask for tokens that should compute loss\n",
    "        hole_pos=[] # initialize holes position list with last padding token position\n",
    "        for start_pos, end_pos in zip(sptk_b_indices, sptk_e_indices):\n",
    "            loss_mask[b][start_pos+1:end_pos] = 1\n",
    "            hole_pos.append(start_pos.item())\n",
    "            hole_pos.append(end_pos.item())\n",
    "        hole_pos.append(seq_len-right_pad_tokens)\n",
    "        assert new_input_ids[b][seq_len-right_pad_tokens]==pad_token_id\n",
    "        \n",
    "        # shift right to fill the wholes\n",
    "        holes_to_fill=1\n",
    "        for i in range(0,len(hole_pos)-1):\n",
    "            start_pos = hole_pos[i]\n",
    "            end_pos = hole_pos[i+1]\n",
    "            new_loss_mask[b,start_pos+1-holes_to_fill:end_pos-holes_to_fill]=loss_mask[b,start_pos+1:end_pos]\n",
    "            new_input_ids[b,start_pos+1-holes_to_fill:end_pos-holes_to_fill]=input_ids[b,start_pos+1:end_pos]\n",
    "            new_attention_mask[b,start_pos+1-holes_to_fill:end_pos-holes_to_fill]=attention_mask[b,start_pos+1:end_pos]\n",
    "            holes_to_fill+=1\n",
    "\n",
    "        valid_tokens = seq_len-right_pad_tokens-len(hole_pos)+1 # the number of non-special tokens and non-padding tokens\n",
    "        new_loss_mask[b][valid_tokens:]=0\n",
    "        new_input_ids[b][valid_tokens:]=pad_token_id\n",
    "        new_attention_mask[b][valid_tokens:]=0\n",
    "        \n",
    "    return new_input_ids, new_attention_mask, new_loss_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import verl.utils.torch_functional as verl_F\n",
    "import torch\n",
    "prompt_with_chat_template=tokenizer.pad_token                      \n",
    "input_ids,attention_mask=verl_F.tokenize_and_postprocess_data(prompt=prompt_with_chat_template,\n",
    "                                        tokenizer=tokenizer,\n",
    "                                        max_length=1024,\n",
    "                                        pad_token_id=tokenizer.pad_token_id,\n",
    "                                        left_pad=False,\n",
    "                                        truncation=\"error\",\n",
    "                                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([], size=(1, 0)), 'attention_mask': tensor([], size=(1, 0))}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"\", return_tensors='pt', add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151643, 151643, 151643,  ..., 151643, 151643, 151643]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(input_ids[0]))\n",
    "print(attention_mask)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:input_ids.shape:torch.Size([1, 1024])\n",
      "This is a test prompt. This is a test prompt. This is a test prompt.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "new_input_ids, new_attention_mask, new_loss_mask=loss_mask(input_ids, attention_mask)\n",
    "print(tokenizer.decode(new_input_ids[0][:30]))\n",
    "print(new_attention_mask[0][:30])\n",
    "print(new_loss_mask[0][:30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
